{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN4vmiu1a_oM"
   },
   "source": [
    "# <center>Fraud detection project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wdd4tQPBbQt-"
   },
   "source": [
    "## Data importation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Bnz3eEMX5xQK"
   },
   "outputs": [],
   "source": [
    "# Package to import \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.core.common import random_state\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from datetime import datetime\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "RANDOM_STATE = 55\n",
    "MODEL_PATH = \"./Models/\"\n",
    "MODEL_EXTENSION = \".sav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QolVrBMEbgAf"
   },
   "source": [
    "Data's importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "uxUc6pvuZDXm",
    "outputId": "a9843435-8b02-4f75-cfca-b86ae40d76d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        v1        v2        v3        v4        v5        v6        v7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5     2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9     9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         v8        v9  ...       v21       v22       v23       v24       v25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        v26       v27       v28  amount  class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62  False  \n",
       "1  0.125895 -0.008983  0.014724    2.69  False  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66  False  \n",
       "3 -0.221929  0.062723  0.061458  123.50  False  \n",
       "4  0.502292  0.219422  0.215153   69.99  False  \n",
       "5  0.105915  0.253844  0.081080    3.67  False  \n",
       "6 -0.257237  0.034507  0.005168    4.99  False  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80  False  \n",
       "8 -0.384157  0.011747  0.142404   93.20  False  \n",
       "9  0.094199  0.246219  0.083076    3.68  False  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data = pd.read_csv(\"/content/drive/MyDrive/Data/creditcard.csv\", sep=',')\n",
    "except: \n",
    "    data = pd.read_csv(\"./Data/creditcard.csv\", sep=',')\n",
    "    \n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "tFLpGq9XZhbj",
    "outputId": "b6c0306e-3411-499e-e53d-d7423a5c935c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.85958</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>88.34962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.14595</td>\n",
       "      <td>1.95870</td>\n",
       "      <td>1.65131</td>\n",
       "      <td>1.51626</td>\n",
       "      <td>1.41587</td>\n",
       "      <td>1.38025</td>\n",
       "      <td>1.33227</td>\n",
       "      <td>1.23709</td>\n",
       "      <td>1.19435</td>\n",
       "      <td>1.09863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77093</td>\n",
       "      <td>0.73452</td>\n",
       "      <td>0.72570</td>\n",
       "      <td>0.62446</td>\n",
       "      <td>0.60565</td>\n",
       "      <td>0.52128</td>\n",
       "      <td>0.48223</td>\n",
       "      <td>0.40363</td>\n",
       "      <td>0.33008</td>\n",
       "      <td>250.12011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-56.40751</td>\n",
       "      <td>-72.71573</td>\n",
       "      <td>-48.32559</td>\n",
       "      <td>-5.68317</td>\n",
       "      <td>-113.74331</td>\n",
       "      <td>-26.16051</td>\n",
       "      <td>-43.55724</td>\n",
       "      <td>-73.21672</td>\n",
       "      <td>-13.43407</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.49772</td>\n",
       "      <td>-34.83038</td>\n",
       "      <td>-10.93314</td>\n",
       "      <td>-44.80774</td>\n",
       "      <td>-2.83663</td>\n",
       "      <td>-10.29540</td>\n",
       "      <td>-2.60455</td>\n",
       "      <td>-22.56568</td>\n",
       "      <td>-15.43008</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.50000</td>\n",
       "      <td>-0.92037</td>\n",
       "      <td>-0.59855</td>\n",
       "      <td>-0.89036</td>\n",
       "      <td>-0.84864</td>\n",
       "      <td>-0.69160</td>\n",
       "      <td>-0.76830</td>\n",
       "      <td>-0.55408</td>\n",
       "      <td>-0.20863</td>\n",
       "      <td>-0.64310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21172</td>\n",
       "      <td>-0.22839</td>\n",
       "      <td>-0.54235</td>\n",
       "      <td>-0.16185</td>\n",
       "      <td>-0.35459</td>\n",
       "      <td>-0.31715</td>\n",
       "      <td>-0.32698</td>\n",
       "      <td>-0.07084</td>\n",
       "      <td>-0.05296</td>\n",
       "      <td>5.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.00000</td>\n",
       "      <td>0.01811</td>\n",
       "      <td>0.06549</td>\n",
       "      <td>0.17985</td>\n",
       "      <td>-0.01985</td>\n",
       "      <td>-0.05434</td>\n",
       "      <td>-0.27419</td>\n",
       "      <td>0.04010</td>\n",
       "      <td>0.02236</td>\n",
       "      <td>-0.05143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.06248</td>\n",
       "      <td>-0.02945</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>-0.01119</td>\n",
       "      <td>0.04098</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>-0.05214</td>\n",
       "      <td>0.00134</td>\n",
       "      <td>0.01124</td>\n",
       "      <td>22.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.50000</td>\n",
       "      <td>1.31564</td>\n",
       "      <td>0.80372</td>\n",
       "      <td>1.02720</td>\n",
       "      <td>0.74334</td>\n",
       "      <td>0.61193</td>\n",
       "      <td>0.39856</td>\n",
       "      <td>0.57044</td>\n",
       "      <td>0.32735</td>\n",
       "      <td>0.59714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13304</td>\n",
       "      <td>0.18638</td>\n",
       "      <td>0.52855</td>\n",
       "      <td>0.14764</td>\n",
       "      <td>0.43953</td>\n",
       "      <td>0.35072</td>\n",
       "      <td>0.24095</td>\n",
       "      <td>0.09105</td>\n",
       "      <td>0.07828</td>\n",
       "      <td>77.16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.00000</td>\n",
       "      <td>2.45493</td>\n",
       "      <td>22.05773</td>\n",
       "      <td>9.38256</td>\n",
       "      <td>16.87534</td>\n",
       "      <td>34.80167</td>\n",
       "      <td>73.30163</td>\n",
       "      <td>120.58949</td>\n",
       "      <td>20.00721</td>\n",
       "      <td>15.59499</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42090</td>\n",
       "      <td>27.20284</td>\n",
       "      <td>10.50309</td>\n",
       "      <td>22.52841</td>\n",
       "      <td>4.58455</td>\n",
       "      <td>7.51959</td>\n",
       "      <td>3.51735</td>\n",
       "      <td>31.61220</td>\n",
       "      <td>33.84781</td>\n",
       "      <td>25691.16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time            v1            v2            v3            v4  \\\n",
       "count  284807.00000  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean    94813.85958       0.00000       0.00000      -0.00000       0.00000   \n",
       "std     47488.14595       1.95870       1.65131       1.51626       1.41587   \n",
       "min         0.00000     -56.40751     -72.71573     -48.32559      -5.68317   \n",
       "25%     54201.50000      -0.92037      -0.59855      -0.89036      -0.84864   \n",
       "50%     84692.00000       0.01811       0.06549       0.17985      -0.01985   \n",
       "75%    139320.50000       1.31564       0.80372       1.02720       0.74334   \n",
       "max    172792.00000       2.45493      22.05773       9.38256      16.87534   \n",
       "\n",
       "                 v5            v6            v7            v8            v9  \\\n",
       "count  284807.00000  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean       -0.00000       0.00000      -0.00000      -0.00000      -0.00000   \n",
       "std         1.38025       1.33227       1.23709       1.19435       1.09863   \n",
       "min      -113.74331     -26.16051     -43.55724     -73.21672     -13.43407   \n",
       "25%        -0.69160      -0.76830      -0.55408      -0.20863      -0.64310   \n",
       "50%        -0.05434      -0.27419       0.04010       0.02236      -0.05143   \n",
       "75%         0.61193       0.39856       0.57044       0.32735       0.59714   \n",
       "max        34.80167      73.30163     120.58949      20.00721      15.59499   \n",
       "\n",
       "       ...           v20           v21           v22           v23  \\\n",
       "count  ...  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean   ...       0.00000       0.00000       0.00000       0.00000   \n",
       "std    ...       0.77093       0.73452       0.72570       0.62446   \n",
       "min    ...     -54.49772     -34.83038     -10.93314     -44.80774   \n",
       "25%    ...      -0.21172      -0.22839      -0.54235      -0.16185   \n",
       "50%    ...      -0.06248      -0.02945       0.00678      -0.01119   \n",
       "75%    ...       0.13304       0.18638       0.52855       0.14764   \n",
       "max    ...      39.42090      27.20284      10.50309      22.52841   \n",
       "\n",
       "                v24           v25           v26           v27           v28  \\\n",
       "count  284807.00000  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean        0.00000       0.00000       0.00000      -0.00000      -0.00000   \n",
       "std         0.60565       0.52128       0.48223       0.40363       0.33008   \n",
       "min        -2.83663     -10.29540      -2.60455     -22.56568     -15.43008   \n",
       "25%        -0.35459      -0.31715      -0.32698      -0.07084      -0.05296   \n",
       "50%         0.04098       0.01659      -0.05214       0.00134       0.01124   \n",
       "75%         0.43953       0.35072       0.24095       0.09105       0.07828   \n",
       "max         4.58455       7.51959       3.51735      31.61220      33.84781   \n",
       "\n",
       "             amount  \n",
       "count  284807.00000  \n",
       "mean       88.34962  \n",
       "std       250.12011  \n",
       "min         0.00000  \n",
       "25%         5.60000  \n",
       "50%        22.00000  \n",
       "75%        77.16500  \n",
       "max     25691.16000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().apply(lambda s: s.apply('{0:.5f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM8_S7bWZk5w",
    "outputId": "b95056f3-030c-478c-fb70-7cd31aaf6225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['time', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'amount', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Column names: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqHfK9BMZuMJ",
    "outputId": "5ec85b36-81ed-41bc-fc53-c6d2da1e47a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data's shape: (284807, 31)\n",
      "------\n",
      "Data's dtypes:\n",
      "time        int64\n",
      "v1        float64\n",
      "v2        float64\n",
      "v3        float64\n",
      "v4        float64\n",
      "v5        float64\n",
      "v6        float64\n",
      "v7        float64\n",
      "v8        float64\n",
      "v9        float64\n",
      "v10       float64\n",
      "v11       float64\n",
      "v12       float64\n",
      "v13       float64\n",
      "v14       float64\n",
      "v15       float64\n",
      "v16       float64\n",
      "v17       float64\n",
      "v18       float64\n",
      "v19       float64\n",
      "v20       float64\n",
      "v21       float64\n",
      "v22       float64\n",
      "v23       float64\n",
      "v24       float64\n",
      "v25       float64\n",
      "v26       float64\n",
      "v27       float64\n",
      "v28       float64\n",
      "amount    float64\n",
      "class        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data's shape: {data.shape}\\n------\")\n",
    "print(f\"Data's dtypes:\\n{data.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CC6ty61Qcwfr",
    "outputId": "262acabb-c08c-4210-c06d-7a66d795d32a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time      0\n",
       "v1        0\n",
       "v2        0\n",
       "v3        0\n",
       "v4        0\n",
       "v5        0\n",
       "v6        0\n",
       "v7        0\n",
       "v8        0\n",
       "v9        0\n",
       "v10       0\n",
       "v11       0\n",
       "v12       0\n",
       "v13       0\n",
       "v14       0\n",
       "v15       0\n",
       "v16       0\n",
       "v17       0\n",
       "v18       0\n",
       "v19       0\n",
       "v20       0\n",
       "v21       0\n",
       "v22       0\n",
       "v23       0\n",
       "v24       0\n",
       "v25       0\n",
       "v26       0\n",
       "v27       0\n",
       "v28       0\n",
       "amount    0\n",
       "class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgxTjR6pdXkF"
   },
   "source": [
    "There isn't any null observation or missing information in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OtHoTutbnNg"
   },
   "source": [
    "Let's take a look at the *time* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-8cRq8Wa6gV",
    "outputId": "2e3b940e-6fde-4c44-996e-6cf3c652fe11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124592"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['time'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vQvx7Ked94Z"
   },
   "source": [
    "The *time* variable seems to not give any informations, so we chose to delete. We must delete it because it's a counter and it will be the most important variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1XrqBw5md0Vm"
   },
   "outputs": [],
   "source": [
    "data.drop(columns='time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KETP_U1_kHPn"
   },
   "source": [
    "Separating inputs (X) & output (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "2FTm-SDqeZOA",
    "outputId": "7eaa19fd-b561-4c09-dc9b-127d71d981ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v3        v4        v5        v6        v7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         v8        v9       v10  ...       v20       v21       v22       v23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        v24       v25       v26       v27       v28  amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut combiner la ligne 6 ans la 7 \n",
    "X = data.drop(columns=\"class\")\n",
    "print(X.shape)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-ztU3jajjlb",
    "outputId": "ff6c91d0-c000-4c49-8731-61c91c380206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: class, dtype: bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['class'].copy()\n",
    "print(Y.shape)\n",
    "Y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LQjkpQDXi72G"
   },
   "outputs": [],
   "source": [
    "X_normalized = StandardScaler().fit_transform(X)\n",
    "# Become a ndarray it's not a DataFrame anymore\n",
    "Y_prepross = LabelBinarizer().fit_transform(Y)\n",
    "\n",
    "Y_prepross = Y_prepross.reshape((Y_prepross.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "90iPwS9Gle-_"
   },
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(X_normalized, Y_prepross,\\\n",
    "                                                   test_size=0.3, random_state=RANDOM_STATE,\\\n",
    "                                                   stratify=Y_prepross)\n",
    "# Stratify attribute permites use to have the same amount of fraud in our \n",
    "# subdatasets! It's a way to fight against bais du to imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpatXaGemtyH",
    "outputId": "04626526-f36d-4ba1-cbff-6313a9e89884",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:(199364, 29)\n",
      "x_test shape:(85443, 29)\n",
      "y_train shape: (199364,)\n",
      "y_test shape: (85443,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape:{x_train.shape}\\nx_test shape:{x_test.shape}\\ny_train shape: {y_train.shape}\\ny_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPZ87TTi4EQz"
   },
   "source": [
    "Compute fraud rate in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXUutn073pBL",
    "outputId": "b5f25f95-65b7-47a6-85e4-33059b7c6638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud rate: 0.1727%\n"
     ]
    }
   ],
   "source": [
    "fraud_rate = (y_train.sum() + y_test.sum()) / (y_train.shape[0] + y_test.shape[0])\n",
    "# We can also use: \n",
    "# fraud_rate = data['class'].sum() / data.shape[0]\n",
    "print(f\"Fraud rate: {round(fraud_rate * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BBI3kgJN6CE7"
   },
   "outputs": [],
   "source": [
    "def addlabels(x, y):\n",
    "    \"\"\"\n",
    "    Add the corresponding value for each segment of a barplot\n",
    "    \"\"\"\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i]+1, round(y[i], 3), ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_hAPUs-n5qZ7"
   },
   "outputs": [],
   "source": [
    "def plotDistribution(result_dict: dict, title: str, x_label: str, absolute=True) -> None:\n",
    "    \"\"\"\n",
    "    Display a barplot with absolute value or relative value\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    if absolute:\n",
    "        plt.bar(result_dict.keys(), result_dict.values(), color= ['red', 'blue', 'cyan', 'orange', 'green', 'yellow'])\n",
    "        plt.title(label=title)\n",
    "        plt.xlabel(x_label)\n",
    "        addlabels(result_dict.keys(), list(result_dict.values()))\n",
    "    else:\n",
    "        ratio = [(i/sum(result_dict.values()))*100 for i in list(result_dict.values())]\n",
    "\n",
    "        plt.bar(result_dict.keys(), ratio, color= ['red', 'blue', 'cyan', 'orange', 'green', 'yellow'])\n",
    "        plt.title(label=title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel('en %')\n",
    "        addlabels(result_dict.keys(), ratio)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "4wg8KoTZ5uKt",
    "outputId": "3509cf59-edc4-4b03-ed44-c8c697838006"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_rate_dict = {\"Fraud\": data[\"class\"].sum(), \"Not a Fraud\": (data['class'] == False).sum()}\n",
    "\n",
    "plotDistribution(fraud_rate_dict, \"Fraud Rate\", \"\", absolute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xc1mpjx_6VLk",
    "outputId": "66a07654-6e64-4b18-da5f-6c9d68fce352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we don't miss any observation\n",
    "((data['class'] == False).sum() + data['class'].sum()) == data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlyFn1w38s5o",
    "outputId": "f97b9ae7-dacf-4a7b-8490-452f0d70f1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train fraud rate: 0.1725%\n",
      "\n",
      "y_test fraud rate: 0.1732%\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train fraud rate: {round((y_train.sum()/y_train.shape[0])*100, 4)}%\\n\")\n",
    "print(f\"y_test fraud rate: {round((y_test.sum()/y_test.shape[0])*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Zelg7yeQ_gzD"
   },
   "outputs": [],
   "source": [
    "#TODO: dimensions reduction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Few words before training and testing algorithms__ <br>\n",
    "Warning can appears during finding the best hyperparameters for each algorithm this is normal because some hyperparameters doesn't work together! But there isn't any influence on the algortihm efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use Cross Validation for all classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified_k_fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztvp3CLF_8R6",
    "outputId": "6f6505cf-d1a1-46b8-ecbe-a27b29e52661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score with k=2: 0.6134\n",
      "Mean recall score with k=3: 0.6366\n",
      "Mean recall score with k=4: 0.6308\n",
      "Mean recall score with k=5: 0.6364\n",
      "Mean recall score with k=6: 0.6388\n",
      "Mean recall score with k=7: 0.6338\n",
      "Mean recall score with k=8: 0.6395\n",
      "Mean recall score with k=9: 0.6371\n",
      "Mean recall score with k=10: 0.6302\n",
      "Mean recall score with k=11: 0.6342\n"
     ]
    }
   ],
   "source": [
    "# Useless if using GridSearchCV!\n",
    "# Delete this cell\n",
    "mean_recall_score = []\n",
    "for i in range(2,12):\n",
    "  stratified_k_fold = StratifiedKFold(n_splits=i, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "  cv_lr_results = cross_validate(lr, x_train, y_train, cv=stratified_k_fold,\\\n",
    "                                scoring=\"recall\")\n",
    "  print(f\"Mean recall score with k={i}: {round(cv_lr_results['test_score'].sum() / len(cv_lr_results['test_score']), 4)}\")\n",
    "  mean_recall_score.append(round(cv_lr_results['test_score'].sum() / len(cv_lr_results['test_score']), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we're choosing the best hyperparameters for the Logistic Regression, training the model wiht those hyperparameters and testing the model on the test set. We also compute the recall score on predictions done on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XsswzyIAFGJ1",
    "outputId": "8a2a2506-b0fc-430d-d613-4836368b206b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 240 candidates, totalling 720 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11328/3847762060.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                   n_jobs=-1)\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mlr_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_hpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0my_pred_lr_bp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's use GridSearchCV for testing different hyperparameters for LR\n",
    "start_time = datetime.now()\n",
    "\n",
    "lr_parameters = {\"penalty\": [\"none\", \"l2\", \"l1\", \"elasticnet\"],\n",
    "                 \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "                 \"C\": [0.1, 1, 10],\n",
    "                \"max_iter\": [100, 1000, 10000, 100000]}\n",
    "\n",
    "lr_hpc = GridSearchCV(estimator=lr, \n",
    "                   param_grid=lr_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "lr_model = lr_hpc.fit(x_train, y_train)\n",
    "y_pred_lr_bp = lr_model.predict(x_test)\n",
    "\n",
    "\n",
    "print(\"\\nBest parameters:\", lr_hpc.best_params_)\n",
    "print(\"Best recall score:\", round(lr_hpc.best_score_, 4))\n",
    "print(len(\"Recall score on test set:\")*\"*\")\n",
    "lr_recall = metrics.recall_score(y_test, y_pred_lr_bp)\n",
    "print(\"\\nRecall score on test set:\", round(lr_recall, 4))\n",
    "\n",
    "matrix_lr = metrics.confusion_matrix(y_test, y_pred_lr_bp)\n",
    "sns.heatmap(matrix_lr, annot = True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test with class_weight LogisticRegression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6PL7mC-cnNf",
    "outputId": "38578f36-265f-479d-d21b-60bdc48aa50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "Best parameters: {'max_iter': 100, 'solver': 'newton-cg'}\n",
      "Best recall score: 0.6364\n",
      "*************************\n",
      "\n",
      "Recall score on test set: 0.5946\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:01:00.873844\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "lr_parameters = {\"solver\": [\"newton-cg\", \"liblinear\"],\n",
    "                 \"max_iter\": [100, 1000, 10000, 100000]}\n",
    "\n",
    "lr_hpc = GridSearchCV(estimator=lr, \n",
    "                   param_grid=lr_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "lr_model = lr_hpc.fit(x_train, y_train)\n",
    "y_pred_lr_bp = lr_model.predict(x_test)\n",
    "\n",
    "filename = MODEL_PATH + \"lr_model\" + MODEL_EXTENSION\n",
    "pickle.dump(lr_model, open(filename, 'wb'))\n",
    "\n",
    "print(\"Best parameters:\", lr_hpc.best_params_)\n",
    "print(\"Best recall score:\", round(lr_hpc.best_score_, 4))\n",
    "print(len(\"Recall score on test set:\")*\"*\")\n",
    "print(\"\\nRecall score on test set:\", round(metrics.recall_score(y_test, y_pred_lr_bp), 4))\n",
    "\n",
    "matrix_lr = metrics.confusion_matrix(y_test, y_pred_lr_bp)\n",
    "sns.heatmap(matrix_lr, annot = True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check how many and which parameters are more important to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 6 candidates, totalling 66 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.77016129 0.75       0.76420455 0.75833944        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'gini', 'splitter': 'best'}\n",
      "Best recall score: 0.7702\n",
      "*************************\n",
      "\n",
      "Recall score on test set: 0.6892\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:02:36.738306\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "dt_parameters = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "                \"splitter\": [\"best\", \"random\"]}\n",
    "\n",
    "dt_hpc = GridSearchCV(estimator=dt, \n",
    "                   param_grid=dt_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "dt_model = dt_hpc.fit(x_train, y_train)\n",
    "y_pred_dt_bp = dt_model.predict(x_test)\n",
    "\n",
    "print(\"Best parameters:\", dt_hpc.best_params_)\n",
    "print(\"Best recall score:\", round(dt_hpc.best_score_, 4))\n",
    "print(len(\"Recall score on test set:\")*\"*\")\n",
    "dt_recall = metrics.recall_score(y_test, y_pred_dt_bp)\n",
    "print(\"\\nRecall score on test set:\", round(dt_recall, 4))\n",
    "\n",
    "matrix_dt = metrics.confusion_matrix(y_test, y_pred_dt_bp)\n",
    "sns.heatmap(matrix_dt, annot = True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters: \n",
    "- Criterion: *insert here*\n",
    "- Splitter: *insert here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 11 folds for each of 3 candidates, totalling 33 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [0.7936217  0.79664589        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'criterion': 'entropy'}\n",
      "Best recall score: 0.7966\n",
      "*************************\n",
      "\n",
      "Recall score on test set: 0.723\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 0:25:23.930933\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "rf_parameters = {\"criterion\": [\"gini\", \"entropy\", \"log_loss\"]}\n",
    "\n",
    "rf_hpc = GridSearchCV(estimator=rf, \n",
    "                   param_grid=rf_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                  n_jobs=-1)\n",
    "\n",
    "rf_model = rf_hpc.fit(x_train, y_train)\n",
    "y_pred_rf_bp = rf_model.predict(x_test)\n",
    "\n",
    "print(\"Best parameters:\", rf_hpc.best_params_)\n",
    "print(\"Best recall score:\", round(rf_hpc.best_score_, 4))\n",
    "print(len(\"Recall score on test set:\")*\"*\")\n",
    "rf_recall = metrics.recall_score(y_test, y_pred_rf_bp)\n",
    "print(\"\\nRecall score on test set:\", round(rf_recall, 4))\n",
    "\n",
    "matrix_rf = metrics.confusion_matrix(y_test, y_pred_rf_bp)\n",
    "sns.heatmap(matrix_rf, annot = True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best hyperparameters:\n",
    "- Criterion: *insert here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(cache_size=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DO NOT EXECUTE THE NEXT CELL__ <br>\n",
    "SVC classifier doesn't stop running! There's too much data for the training set! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "svc_parameters = {\"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]}\n",
    "\n",
    "svc_hpc = GridSearchCV(estimator=svc, \n",
    "                   param_grid=svc_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "svc_model = svc_hpc.fit(x_train, y_train)\n",
    "y_pred_svc_bp = svc_model.predict(x_test)\n",
    "\n",
    "print(\"Best parameters:\", svc_hpc.best_params_)\n",
    "print(\"Best recall score:\", round(svc_hpc.best_score_, 4))\n",
    "print(len(\"Recall score on test set:\")*\"*\")\n",
    "svc_recall = metrics.recall_score(y_test, y_pred_svc_bp)\n",
    "print(\"\\nRecall score on test set:\", round(svc_recall, 4))\n",
    "\n",
    "matrix_svc = metrics.confusion_matrix(y_test, y_pred_svc_bp)\n",
    "sns.heatmap(matrix_svc, annot = True, fmt='g', cmap=\"Blues\")\n",
    "plt.show()\n",
    "\n",
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not using *precomputed* kernel because it need a (n_sample, n_sample) matrix as input and not the usual (n_samples, n_features) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recall_score_global = {\"Logistic Regression\": lr_hpc.best_score_, \"Decision Tree\": dt_hpc.best_score_, \"Random Forest\": rf_hpc.best_score_, \"SVC\": svc_hpc.best_score_}\n",
    "# test_recall_score_global = {\"Logistic Regression\": lr_recall, \"Decision Tree\": dt_recall, \"Random Forest\": rf_recall, \"SVC\": svc_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Decision Tree': 0.7701612903225807,\n",
      " 'Logistic Regression': 0.6364023870417732,\n",
      " 'Random Forest': 0.7966458944281524}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_recall_score_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

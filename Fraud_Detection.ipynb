{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN4vmiu1a_oM"
   },
   "source": [
    "#Fraud detection project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wdd4tQPBbQt-"
   },
   "source": [
    "## Data importation and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdoqwtQqX3CS",
    "outputId": "22184239-6bad-466f-c26c-595960bc2691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Bnz3eEMX5xQK"
   },
   "outputs": [],
   "source": [
    "# Package to import \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, StratifiedKFold\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas.core.common import random_state\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QolVrBMEbgAf"
   },
   "source": [
    "Data's importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "uxUc6pvuZDXm",
    "outputId": "a9843435-8b02-4f75-cfca-b86ae40d76d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time        v1        v2        v3        v4        v5        v6        v7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "5     2 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n",
       "6     4  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n",
       "7     7 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n",
       "8     7 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n",
       "9     9 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n",
       "\n",
       "         v8        v9  ...       v21       v22       v23       v24       v25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "5  0.260314 -0.568671  ... -0.208254 -0.559825 -0.026398 -0.371427 -0.232794   \n",
       "6  0.081213  0.464960  ... -0.167716 -0.270710 -0.154104 -0.780055  0.750137   \n",
       "7 -3.807864  0.615375  ...  1.943465 -1.015455  0.057504 -0.649709 -0.415267   \n",
       "8  0.851084 -0.392048  ... -0.073425 -0.268092 -0.204233  1.011592  0.373205   \n",
       "9  0.069539 -0.736727  ... -0.246914 -0.633753 -0.120794 -0.385050 -0.069733   \n",
       "\n",
       "        v26       v27       v28  amount  class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62  False  \n",
       "1  0.125895 -0.008983  0.014724    2.69  False  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66  False  \n",
       "3 -0.221929  0.062723  0.061458  123.50  False  \n",
       "4  0.502292  0.219422  0.215153   69.99  False  \n",
       "5  0.105915  0.253844  0.081080    3.67  False  \n",
       "6 -0.257237  0.034507  0.005168    4.99  False  \n",
       "7 -0.051634 -1.206921 -1.085339   40.80  False  \n",
       "8 -0.384157  0.011747  0.142404   93.20  False  \n",
       "9  0.094199  0.246219  0.083076    3.68  False  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"/content/drive/MyDrive/Data/creditcard.csv\", sep=',')\n",
    "except: \n",
    "    data = pd.read_csv(\"./Data/creditcard.csv\", sep=',')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "tFLpGq9XZhbj",
    "outputId": "b6c0306e-3411-499e-e53d-d7423a5c935c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-69b2fc1c-45bf-48a8-9221-5f9da3da7387\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>...</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "      <td>284807.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.85958</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>88.34962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.14595</td>\n",
       "      <td>1.95870</td>\n",
       "      <td>1.65131</td>\n",
       "      <td>1.51626</td>\n",
       "      <td>1.41587</td>\n",
       "      <td>1.38025</td>\n",
       "      <td>1.33227</td>\n",
       "      <td>1.23709</td>\n",
       "      <td>1.19435</td>\n",
       "      <td>1.09863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77093</td>\n",
       "      <td>0.73452</td>\n",
       "      <td>0.72570</td>\n",
       "      <td>0.62446</td>\n",
       "      <td>0.60565</td>\n",
       "      <td>0.52128</td>\n",
       "      <td>0.48223</td>\n",
       "      <td>0.40363</td>\n",
       "      <td>0.33008</td>\n",
       "      <td>250.12011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>-56.40751</td>\n",
       "      <td>-72.71573</td>\n",
       "      <td>-48.32559</td>\n",
       "      <td>-5.68317</td>\n",
       "      <td>-113.74331</td>\n",
       "      <td>-26.16051</td>\n",
       "      <td>-43.55724</td>\n",
       "      <td>-73.21672</td>\n",
       "      <td>-13.43407</td>\n",
       "      <td>...</td>\n",
       "      <td>-54.49772</td>\n",
       "      <td>-34.83038</td>\n",
       "      <td>-10.93314</td>\n",
       "      <td>-44.80774</td>\n",
       "      <td>-2.83663</td>\n",
       "      <td>-10.29540</td>\n",
       "      <td>-2.60455</td>\n",
       "      <td>-22.56568</td>\n",
       "      <td>-15.43008</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.50000</td>\n",
       "      <td>-0.92037</td>\n",
       "      <td>-0.59855</td>\n",
       "      <td>-0.89036</td>\n",
       "      <td>-0.84864</td>\n",
       "      <td>-0.69160</td>\n",
       "      <td>-0.76830</td>\n",
       "      <td>-0.55408</td>\n",
       "      <td>-0.20863</td>\n",
       "      <td>-0.64310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.21172</td>\n",
       "      <td>-0.22839</td>\n",
       "      <td>-0.54235</td>\n",
       "      <td>-0.16185</td>\n",
       "      <td>-0.35459</td>\n",
       "      <td>-0.31715</td>\n",
       "      <td>-0.32698</td>\n",
       "      <td>-0.07084</td>\n",
       "      <td>-0.05296</td>\n",
       "      <td>5.60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.00000</td>\n",
       "      <td>0.01811</td>\n",
       "      <td>0.06549</td>\n",
       "      <td>0.17985</td>\n",
       "      <td>-0.01985</td>\n",
       "      <td>-0.05434</td>\n",
       "      <td>-0.27419</td>\n",
       "      <td>0.04010</td>\n",
       "      <td>0.02236</td>\n",
       "      <td>-0.05143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.06248</td>\n",
       "      <td>-0.02945</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>-0.01119</td>\n",
       "      <td>0.04098</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>-0.05214</td>\n",
       "      <td>0.00134</td>\n",
       "      <td>0.01124</td>\n",
       "      <td>22.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.50000</td>\n",
       "      <td>1.31564</td>\n",
       "      <td>0.80372</td>\n",
       "      <td>1.02720</td>\n",
       "      <td>0.74334</td>\n",
       "      <td>0.61193</td>\n",
       "      <td>0.39856</td>\n",
       "      <td>0.57044</td>\n",
       "      <td>0.32735</td>\n",
       "      <td>0.59714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.13304</td>\n",
       "      <td>0.18638</td>\n",
       "      <td>0.52855</td>\n",
       "      <td>0.14764</td>\n",
       "      <td>0.43953</td>\n",
       "      <td>0.35072</td>\n",
       "      <td>0.24095</td>\n",
       "      <td>0.09105</td>\n",
       "      <td>0.07828</td>\n",
       "      <td>77.16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.00000</td>\n",
       "      <td>2.45493</td>\n",
       "      <td>22.05773</td>\n",
       "      <td>9.38256</td>\n",
       "      <td>16.87534</td>\n",
       "      <td>34.80167</td>\n",
       "      <td>73.30163</td>\n",
       "      <td>120.58949</td>\n",
       "      <td>20.00721</td>\n",
       "      <td>15.59499</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42090</td>\n",
       "      <td>27.20284</td>\n",
       "      <td>10.50309</td>\n",
       "      <td>22.52841</td>\n",
       "      <td>4.58455</td>\n",
       "      <td>7.51959</td>\n",
       "      <td>3.51735</td>\n",
       "      <td>31.61220</td>\n",
       "      <td>33.84781</td>\n",
       "      <td>25691.16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-69b2fc1c-45bf-48a8-9221-5f9da3da7387')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-69b2fc1c-45bf-48a8-9221-5f9da3da7387 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-69b2fc1c-45bf-48a8-9221-5f9da3da7387');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               time            v1            v2            v3            v4  \\\n",
       "count  284807.00000  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean    94813.85958       0.00000       0.00000      -0.00000       0.00000   \n",
       "std     47488.14595       1.95870       1.65131       1.51626       1.41587   \n",
       "min         0.00000     -56.40751     -72.71573     -48.32559      -5.68317   \n",
       "25%     54201.50000      -0.92037      -0.59855      -0.89036      -0.84864   \n",
       "50%     84692.00000       0.01811       0.06549       0.17985      -0.01985   \n",
       "75%    139320.50000       1.31564       0.80372       1.02720       0.74334   \n",
       "max    172792.00000       2.45493      22.05773       9.38256      16.87534   \n",
       "\n",
       "                 v5            v6            v7            v8            v9  \\\n",
       "count  284807.00000  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean        0.00000       0.00000      -0.00000       0.00000      -0.00000   \n",
       "std         1.38025       1.33227       1.23709       1.19435       1.09863   \n",
       "min      -113.74331     -26.16051     -43.55724     -73.21672     -13.43407   \n",
       "25%        -0.69160      -0.76830      -0.55408      -0.20863      -0.64310   \n",
       "50%        -0.05434      -0.27419       0.04010       0.02236      -0.05143   \n",
       "75%         0.61193       0.39856       0.57044       0.32735       0.59714   \n",
       "max        34.80167      73.30163     120.58949      20.00721      15.59499   \n",
       "\n",
       "       ...           v20           v21           v22           v23  \\\n",
       "count  ...  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean   ...       0.00000       0.00000      -0.00000       0.00000   \n",
       "std    ...       0.77093       0.73452       0.72570       0.62446   \n",
       "min    ...     -54.49772     -34.83038     -10.93314     -44.80774   \n",
       "25%    ...      -0.21172      -0.22839      -0.54235      -0.16185   \n",
       "50%    ...      -0.06248      -0.02945       0.00678      -0.01119   \n",
       "75%    ...       0.13304       0.18638       0.52855       0.14764   \n",
       "max    ...      39.42090      27.20284      10.50309      22.52841   \n",
       "\n",
       "                v24           v25           v26           v27           v28  \\\n",
       "count  284807.00000  284807.00000  284807.00000  284807.00000  284807.00000   \n",
       "mean        0.00000       0.00000       0.00000      -0.00000      -0.00000   \n",
       "std         0.60565       0.52128       0.48223       0.40363       0.33008   \n",
       "min        -2.83663     -10.29540      -2.60455     -22.56568     -15.43008   \n",
       "25%        -0.35459      -0.31715      -0.32698      -0.07084      -0.05296   \n",
       "50%         0.04098       0.01659      -0.05214       0.00134       0.01124   \n",
       "75%         0.43953       0.35072       0.24095       0.09105       0.07828   \n",
       "max         4.58455       7.51959       3.51735      31.61220      33.84781   \n",
       "\n",
       "             amount  \n",
       "count  284807.00000  \n",
       "mean       88.34962  \n",
       "std       250.12011  \n",
       "min         0.00000  \n",
       "25%         5.60000  \n",
       "50%        22.00000  \n",
       "75%        77.16500  \n",
       "max     25691.16000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().apply(lambda s: s.apply('{0:.5f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM8_S7bWZk5w",
    "outputId": "b95056f3-030c-478c-fb70-7cd31aaf6225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['time', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'amount', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Column names: {list(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kqHfK9BMZuMJ",
    "outputId": "5ec85b36-81ed-41bc-fc53-c6d2da1e47a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data's shape: (284807, 31)\n",
      "------\n",
      "Data's dtypes:\n",
      "time        int64\n",
      "v1        float64\n",
      "v2        float64\n",
      "v3        float64\n",
      "v4        float64\n",
      "v5        float64\n",
      "v6        float64\n",
      "v7        float64\n",
      "v8        float64\n",
      "v9        float64\n",
      "v10       float64\n",
      "v11       float64\n",
      "v12       float64\n",
      "v13       float64\n",
      "v14       float64\n",
      "v15       float64\n",
      "v16       float64\n",
      "v17       float64\n",
      "v18       float64\n",
      "v19       float64\n",
      "v20       float64\n",
      "v21       float64\n",
      "v22       float64\n",
      "v23       float64\n",
      "v24       float64\n",
      "v25       float64\n",
      "v26       float64\n",
      "v27       float64\n",
      "v28       float64\n",
      "amount    float64\n",
      "class        bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data's shape: {data.shape}\\n------\")\n",
    "print(f\"Data's dtypes:\\n{data.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CC6ty61Qcwfr",
    "outputId": "262acabb-c08c-4210-c06d-7a66d795d32a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time      0\n",
       "v1        0\n",
       "v2        0\n",
       "v3        0\n",
       "v4        0\n",
       "v5        0\n",
       "v6        0\n",
       "v7        0\n",
       "v8        0\n",
       "v9        0\n",
       "v10       0\n",
       "v11       0\n",
       "v12       0\n",
       "v13       0\n",
       "v14       0\n",
       "v15       0\n",
       "v16       0\n",
       "v17       0\n",
       "v18       0\n",
       "v19       0\n",
       "v20       0\n",
       "v21       0\n",
       "v22       0\n",
       "v23       0\n",
       "v24       0\n",
       "v25       0\n",
       "v26       0\n",
       "v27       0\n",
       "v28       0\n",
       "amount    0\n",
       "class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgxTjR6pdXkF"
   },
   "source": [
    "There isn't any null observation or missing information in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OtHoTutbnNg"
   },
   "source": [
    "Let's take a look at the *time* variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-8cRq8Wa6gV",
    "outputId": "2e3b940e-6fde-4c44-996e-6cf3c652fe11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124592"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['time'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vQvx7Ked94Z"
   },
   "source": [
    "The *time* variable seems to not give any informations, so we chose to delete. We must delete it because it's a counter and it will be the most important variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1XrqBw5md0Vm"
   },
   "outputs": [],
   "source": [
    "data.drop(columns='time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KETP_U1_kHPn"
   },
   "source": [
    "Separating inputs (X) & output (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "2FTm-SDqeZOA",
    "outputId": "7eaa19fd-b561-4c09-dc9b-127d71d981ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "      <th>v6</th>\n",
       "      <th>v7</th>\n",
       "      <th>v8</th>\n",
       "      <th>v9</th>\n",
       "      <th>v10</th>\n",
       "      <th>...</th>\n",
       "      <th>v20</th>\n",
       "      <th>v21</th>\n",
       "      <th>v22</th>\n",
       "      <th>v23</th>\n",
       "      <th>v24</th>\n",
       "      <th>v25</th>\n",
       "      <th>v26</th>\n",
       "      <th>v27</th>\n",
       "      <th>v28</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         v1        v2        v3        v4        v5        v6        v7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         v8        v9       v10  ...       v20       v21       v22       v23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        v24       v25       v26       v27       v28  amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On peut combiner la ligne 6 ans la 7 \n",
    "X = data.drop(columns=\"class\")\n",
    "print(X.shape)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-ztU3jajjlb",
    "outputId": "ff6c91d0-c000-4c49-8731-61c91c380206"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: class, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['class'].copy()\n",
    "print(Y.shape)\n",
    "Y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LQjkpQDXi72G"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_normalized = StandardScaler().fit_transform(X)\n",
    "# Become a ndarray it's not a DataFrame anymore\n",
    "Y_prepross = LabelBinarizer().fit_transform(Y)\n",
    "\n",
    "Y_prepross = Y_prepross.reshape((Y_prepross.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "90iPwS9Gle-_"
   },
   "outputs": [],
   "source": [
    "x_train, x_test,y_train, y_test = train_test_split(X_normalized, Y_prepross,\\\n",
    "                                                   test_size=0.3, random_state=45,\\\n",
    "                                                   stratify=Y_prepross)\n",
    "# Stratify attribute permites use to have the same amount of fraud in our \n",
    "# subdatasets! It's a way to fight against bais du to imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpatXaGemtyH",
    "outputId": "04626526-f36d-4ba1-cbff-6313a9e89884",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:(199364, 29)\n",
      "x_test shape:(85443, 29)\n",
      "y_train shape: (199364,)\n",
      "y_test shape: (85443,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train shape:{x_train.shape}\\nx_test shape:{x_test.shape}\\ny_train shape: {y_train.shape}\\ny_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPZ87TTi4EQz"
   },
   "source": [
    "Compute fraud rate in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXUutn073pBL",
    "outputId": "b5f25f95-65b7-47a6-85e4-33059b7c6638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud rate: 0.1727%\n"
     ]
    }
   ],
   "source": [
    "fraud_rate = (y_train.sum() + y_test.sum()) / (y_train.shape[0] + y_test.shape[0])\n",
    "# We can also use: \n",
    "# fraud_rate = data['class'].sum() / data.shape[0]\n",
    "print(f\"Fraud rate: {round(fraud_rate * 100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BBI3kgJN6CE7"
   },
   "outputs": [],
   "source": [
    "def addlabels(x, y):\n",
    "    \"\"\"\n",
    "    Add the corresponding value for each segment of a barplot\n",
    "    \"\"\"\n",
    "    for i in range(len(x)):\n",
    "        plt.text(i, y[i], round(y[i], 3), ha='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_hAPUs-n5qZ7"
   },
   "outputs": [],
   "source": [
    "def plotDistribution(result_dict: dict, title: str, x_label: str, absolute=True) -> None:\n",
    "    \"\"\"\n",
    "    Display a barplot with absolute value or relative value\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    if absolute:\n",
    "        plt.bar(result_dict.keys(), result_dict.values(), color= ['red', 'blue', 'cyan', 'orange', 'green', 'yellow'])\n",
    "        plt.title(label=title)\n",
    "        plt.xlabel(x_label)\n",
    "        addlabels(result_dict.keys(), list(result_dict.values()))\n",
    "    else:\n",
    "        ratio = [(i/sum(result_dict.values()))*100 for i in list(result_dict.values())]\n",
    "\n",
    "        plt.bar(result_dict.keys(), ratio, color= ['red', 'blue', 'cyan', 'orange', 'green', 'yellow'])\n",
    "        plt.title(label=title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel('en %')\n",
    "        addlabels(result_dict.keys(), ratio)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "4wg8KoTZ5uKt",
    "outputId": "3509cf59-edc4-4b03-ed44-c8c697838006"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsgAAAI4CAYAAAB3OR9vAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfGklEQVR4nO3de5TkdXnn8c8jAxI03OJAuKOIIo6IOiSQi5olEHW9oFmzILpocFnPmtXkBKOJMequBBI1AVaMawwJIjKKoEwQjTjRRVfFDAiKAjtuUIZLZEJEFFAEvvtHF/jMMAwN2F2t83qd06erfrd6mnOmePevf1VVY4wAAAAzHjLtAQAAYCERyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAb4KVRVf1dVb5n2HAA/iQQywByqqm9U1a1V9b32teOUZ3ppVd0xmeWmqrqkqp59P/b/RlX9+lzOCDBNAhlg7j1njPHw9nVtX1lVi6Yw0+fHGA9PsnWSdyZZVlVbT2EOgAVHIANMQVWNqnplVa1Ksmqy7ISqWj05q3thVf1q236tSyaq6ulVdXW7/6SquqiqvltVH0iy+WzmGGPcmeTUJA9LsufkWHtU1T9W1Q1V9a9Vddpd8VxVpybZNcnfT85A/8Fk+f5V9bmqunFyRvrpD+a/D8A0CWSA6TkkyS8m2Xty/5+S7Jtk2yTvT3JGVd1n6FbVZkk+kpnQ3TbJGUl+czYDVNUmSV6W5IdJvnnX4iTHJtkxyeOS7JLkTUkyxnhJkqvyo7Pif15VOyX5aJK3TB7/6CRnVtXi2cwAsNAIZIC595HJmdUbq+ojbfmxY4x/G2PcmiRjjPeNMW4YY9w+xnh7kocmeewsjr9/kk2THD/G+OEY40OZie0N7lNVNyb5fpK3JXnxGOP6yRxfH2OcN8b4wRhjTZK/SPK0DRzrxUnOHWOcO8a4c4xxXpKVSZ41i9kBFhyBDDD3DhljbD35OqQtX903qqrfr6rLquo7k3jdKskjZnH8HZNcM8YYbdk3723jiS+MMbZOsk2S5Un65RzbVdWyqrqmqm5K8r77mGO3JC9svwTcmORXkuwwi9kBFhyBDDA9dwft5Hrj1yb5rSTbTOL1O5m53CFJbk6yRdv359vt65LsVFXVlu06qwHG+F6S/5rkJVX1pMniYyez7TPG2DIzZ4j7scfaR8nqJKe2XwK2HmM8bIxx3GxmAFhoBDLAwvCzSW5PsibJoqr6kyRbtvUXJ3lWVW1bVT+f5Hfbus9P9n1VVS2qqhck+YXZPvAY44Yk70nyJ22W7yW5cXJ98WvW2eVbSR7V7r8vyXOq6jeqapOq2nzyIsKdZzsDwEIikAEWhn9I8rEk/zczl0d8P2tfgnFqkkuSfCPJJ5J84K4VY4zbkrwgyUuTfDvJf0xy1v18/OMzE+D7JHlzkidn5gz2R9dzrGOT/PHkcoqjxxirkzwvyR9lJvBXZyaq/T8G+IlUa1+yBgAAGze/3QMAQCOQAQCgEcgAANAIZAAAaBZNe4AH4xGPeMTYfffdpz0GAAA/gS688MJ/HWMsXnf5T3Qg77777lm5cuW0xwAA4CdQVa33U0ddYgEAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwA3C8nnHBClixZksc//vE5/vjjkySXXHJJDjjggDzhCU/Ic57znNx0003r3fcv//Iv8/jHPz5LlizJYYcdlu9///tJkte85jXZa6+9ss8+++T5z39+brzxxiTJaaedln333ffur4c85CG5+OKL5+GnZGMmkAGAWbv00kvz13/91/niF7+YSy65JOecc05WrVqVl7/85TnuuOPyla98Jc9//vPz1re+9R77XnPNNTnxxBOzcuXKXHrppbnjjjuybNmyJMlBBx2USy+9NF/+8pfzmMc8Jscee2yS5PDDD8/FF1+ciy++OKeeemp233337LvvvvP5I7MREsgAwKxddtll2X///bPFFltk0aJFedrTnpYPf/jDueKKK/LUpz41yUzsnnnmmevd//bbb8+tt96a22+/Pbfcckt23HHHJMnBBx+cRYsWJUn233//XH311ffY9/TTT89hhx02Rz8Z/MicBXJVnVxV11fVpW3ZtlV1XlWtmnzfpq37w6r6elVdUVW/MVdzAQAP3JIlS3L++efnhhtuyC233JJzzz03q1evzpIlS7J8+fIkyRlnnJHVq1ffY9+ddtopRx99dHbdddfssMMO2WqrrXLwwQffY7uTTz45z3zmM++x/AMf+IBAZl7M5Rnkv0vyjHWWvS7JijHGnklWTO6nqvZOcmiSx0/2eWdVbTKHswEAD8DjHve4vPa1r81BBx2UZzzjGXniE5+YRYsW5eSTT85JJ52UpzzlKfnud7+bzTbb7B77fvvb387ZZ5+dK6+8Mtdee21uvvnmvO9971trm2OOOSaLFi3K4YcfvtbyCy64IFtssUWWLFkypz8fJHMYyGOM85P82zqLn5fklMntU5Ic0pYvG2P8YIxxZZKvJ/mFuZoNAHjgjjzyyFx00UU5//zzs+2222bPPffMXnvtlU984hO58MILc9hhh2WPPfa4x36f/OQn88hHPjKLFy/Opptumhe84AX53Oc+d/f6U045Jeecc05OO+20VNVa+y5btszZY+bNfF+DvP0Y47okmXzfbrJ8pyT9bzFXT5bdQ1UdVVUrq2rlmjVr5nRYAOCerr/++iTJVVddlbPOOiuHHXbY3cvuvPPOvOUtb8krXvGKe+y366675gtf+EJuueWWjDGyYsWKPO5xj0uSfPzjH8+f/dmfZfny5dliiy3W2u/OO+/MGWeckUMPPXSOfzKYUWOMuTt41e5JzhljLJncv3GMsXVb/+0xxjZVdVKSz48x3jdZ/jdJzh1jrP8K/4mlS5eOlStXztn8ADx465wI5KfCrya5IcmmSf4iyYFJTkhy0mT9C5Icm6SSXJvk5UnOnax7Y5IPJFmU5ElJ3pPkoUkeneQHSX5ust3+Sd41uf3pzFyV+YU5+nmYtjnM0Q2qqgvHGEvXXb5onuf4VlXtMMa4rqp2SHL9ZPnVSXZp2+2cmX9RAMCC85n1LHv15GtdO+ZHcZwkb558revrG3i8p0ccM5/m+xKL5UmOmNw+IsnZbfmhVfXQqnpkkj2TfHGeZwMAgLk7g1xVp2fmV75HVNXVmfmbynFJPlhVRya5KskLk2SM8dWq+mCSryW5Pckrxxh3zNVsAABwb+YskMcY9/ZS0wPvZftjkhwzV/MAAMBs+CQ9AABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAGoEMAACNQAYAgEYgAwBAI5ABAKARyAAA0AhkAABoBDIAADQCGQAAmqkEclX9XlV9taourarTq2rzqtq2qs6rqlWT79tMYzYAADZu8x7IVbVTklclWTrGWJJkkySHJnldkhVjjD2TrJjcBwCAeTWtSywWJfmZqlqUZIsk1yZ5XpJTJutPSXLIdEYDAGBjNu+BPMa4JsnbklyV5Lok3xljfCLJ9mOM6ybbXJdku/XtX1VHVdXKqlq5Zs2a+RobAICNxDQusdgmM2eLH5lkxyQPq6oXz3b/Mca7xxhLxxhLFy9ePFdjAgCwkZrGJRa/nuTKMcaaMcYPk5yV5JeSfKuqdkiSyffrpzAbAAAbuWkE8lVJ9q+qLaqqkhyY5LIky5McMdnmiCRnT2E2AAA2covm+wHHGBdU1YeSXJTk9iRfSvLuJA9P8sGqOjIzEf3C+Z4NAADmPZCTZIzxxiRvXGfxDzJzNhkAAKbGJ+kBAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoJlKIFfV1lX1oaq6vKouq6oDqmrbqjqvqlZNvm8zjdkAANi4TesM8glJPj7G2CvJE5NcluR1SVaMMfZMsmJyHwAA5tW8B3JVbZnkqUn+JknGGLeNMW5M8rwkp0w2OyXJIfM9GwAATOMM8qOSrEnyt1X1pap6T1U9LMn2Y4zrkmTyfbv17VxVR1XVyqpauWbNmvmbGgCAjcI0AnlRkicn+asxxpOS3Jz7cTnFGOPdY4ylY4ylixcvnqsZAQDYSE0jkK9OcvUY44LJ/Q9lJpi/VVU7JMnk+/VTmA0AgI3cvAfyGONfkqyuqsdOFh2Y5GtJlic5YrLsiCRnz/dsAACwaEqP+9+SnFZVmyX55yQvy0ysf7CqjkxyVZIXTmk2AAA2YlMJ5DHGxUmWrmfVgfM8CgAArMUn6QEAQCOQAQCgEcgAANAIZAAAaAQyAAA0AhkAABqBDAAAjUAGAIBGIAMAQCOQAQCgEcgAANAIZAAAaAQyAAA0AhkAABqBDAAAjUAGAIBGIAMAQCOQAQCgEcgAANAIZAAAaAQyAAA0i2a7YVVtnuTwJFskef8Y44Y5mwoAAKbk/pxBPiEzQf39JB+Zk2kAAGDK7jWQq+r9VbVHW7RtktOSnJ5km7keDAAApmFDl1j8cZK3VNW1Sf5HkrclWZ5k8yRvmvvRAABg/t1rII8x/jnJi6rqV5J8IMlHkxw0xrhjvoYDAID5tqFLLLapqlcm2TvJbyX5TpJ/qKpnz9dwAAAw3zb0Ir2PJPlBZi6pOHWM8d4kz0nylKpaPg+zAQDAvNvQNcg/l+T9SX4myX9KkjHGrUneXFU7zMNsAAAw7zYUyH+S5LwkdyR5XV8xxrhuLocCAIBp2dCL9M5KctY8zgIAAFPno6YBAKARyAAA0AhkAABoNvQivSRJVS1O8p+T7N63H2P89tyNBQAA03GfgZzk7CSfSfLJzLyjBQAA/NSaTSBvMcZ47ZxPAgAAC8BsrkE+p6qeNeeTAADAAjCbQH51ZiL5+1V1U1V9t6pumuvBAABgGu7zEosxxs/OxyAAALAQ3OcZ5Jrx4qp6w+T+LlX1C3M/GgAAzL/ZXGLxziQHJHnR5P73kpw0ZxMBAMAUzeZdLH5xjPHkqvpSkowxvl1Vm83xXAAAMBWzOYP8w6raJMlI7v7gkDvndCoAAJiS2QTyiUk+nGS7qjomyWeT/OmcTgUAAFMym3exOK2qLkxyYJJKcsgY47I5nwwAAKZgNtcgZ4xxeZLL53gWAACYutlcYgEAABsNgQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAztUCuqk2q6ktVdc7k/rZVdV5VrZp832ZaswEAsPGa5hnkVye5rN1/XZIVY4w9k6yY3AcAgHk1lUCuqp2T/Psk72mLn5fklMntU5IcMs9jAQDA1M4gH5/kD5Lc2ZZtP8a4Lkkm37db345VdVRVrayqlWvWrJnzQQEA2LjMeyBX1bOTXD/GuPCB7D/GePcYY+kYY+nixYt/zNMBALCxWzSFx/zlJM+tqmcl2TzJllX1viTfqqodxhjXVdUOSa6fwmwAAGzk5v0M8hjjD8cYO48xdk9yaJJ/HGO8OMnyJEdMNjsiydnzPRsAACyk90E+LslBVbUqyUGT+wAAMK+mcYnF3cYYn07y6cntG5IcOM15AABgIZ1BBgCAqRPIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQzHsgV9UuVfWpqrqsqr5aVa+eLN+2qs6rqlWT79vM92wAADCNM8i3J/n9Mcbjkuyf5JVVtXeS1yVZMcbYM8mKyX0AAJhX8x7IY4zrxhgXTW5/N8llSXZK8rwkp0w2OyXJIfM9GwAATPUa5KraPcmTklyQZPsxxnXJTEQn2e5e9jmqqlZW1co1a9bM26wAAGwcphbIVfXwJGcm+d0xxk2z3W+M8e4xxtIxxtLFixfP3YAAAGyUphLIVbVpZuL4tDHGWZPF36qqHSbrd0hy/TRmAwBg4zaNd7GoJH+T5LIxxl+0VcuTHDG5fUSSs+d7NgAAWDSFx/zlJC9J8pWquniy7I+SHJfkg1V1ZJKrkrxwCrMBALCRm/dAHmN8Nkndy+oD53MWAABYl0/SAwCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZAAAagQwAAI1ABgCARiADAEAjkAEAoBHIAADQCGQAAGgEMgAANAIZ1vHxj388j33sY/PoRz86xx133D3WX3755TnggAPy0Ic+NG9729vuXn7FFVdk3333vftryy23zPHHH58kecMb3pB99tkn++67bw4++OBce+218/XjAAD3U40xpj3DA7Z06dKxcuXKaY/BT5E77rgjj3nMY3Leeedl5513zn777ZfTTz89e++9993bXH/99fnmN7+Zj3zkI9lmm21y9NFHr/c4O+20Uy644ILstttuuemmm7LlllsmSU488cR87Wtfy7ve9a55+7lgmqqmPQGw0E0rR6vqwjHG0nWXO4MMzRe/+MU8+tGPzqMe9ahsttlmOfTQQ3P22Wevtc12222X/fbbL5tuuum9HmfFihXZY489sttuuyXJ3XGcJDfffHNKMQDAgrVo2gPAQnLNNddkl112ufv+zjvvnAsuuOB+H2fZsmU57LDD1lr2+te/Pu9973uz1VZb5VOf+tSDnhUAmBvOIEOzvkuO7u/Z3ttuuy3Lly/PC1/4wrWWH3PMMVm9enUOP/zwvOMd73hQcwIAc2fBBXJVPaOqrqiqr1fV66Y9DxuXnXfeOatXr777/tVXX50dd9zxfh3jYx/7WJ785Cdn++23X+/6F73oRTnzzDMf1JwAwNxZUIFcVZskOSnJM5PsneSwqtp7w3vBj89+++2XVatW5corr8xtt92WZcuW5bnPfe79Osbpp59+j8srVq1adfft5cuXZ6+99vqxzAsA/PgtqHexqKoDkrxpjPEbk/t/mCRjjGPXt/3U3sXCC6x+qp2b5HeT3JHkt5O8Psld7zfxiiT/kmRpkpsy8xvmw5N8LcmWSW5JskuSf06yVTvmbya5YrL9bpPj7TS3PwbTtoCeW6fNUyZwXxbau1gstED+D0meMcZ4+eT+S5L84hjjd9o2RyU5anL3sZnpDpi2RyT512kPAfATwnMmC8VuY4zF6y5caO9isb7zDGsV/Bjj3UnePT/jwOxU1cr1/QYKwD15zmShW1DXICe5OjN/ob7Lzkl85BgAAPNmoQXyPyXZs6oeWVWbJTk0yfIpzwQAwEZkQV1iMca4vap+J8k/JNkkycljjK9OeSyYDZf9AMye50wWtAX1Ij0AAJi2hXaJBQAATJVABgCARiDDOqrqjqq6uH3tPgeP8Y2qesSP+7gAD0RVjap6e7t/dFW96T72OeTBfNptVT29qr7Tnms/+UCPtYHH2L2qLv1xH5effgvqRXqwQNw6xth3fSuqqjJz7f6d8zsSwJz6QZIXVNWxY4zZfoDHIUnOycyHiT5QnxljPHt9K6pq0Rjj9gdxbHjAnEGG+zA5A3FZVb0zyUVJdqmqv6qqlVX11ap6c9v27jPDVbW0qj49uf1zVfWJqvpSVf2vrP9DcQCm5fbMvLPE7627oqp2q6oVVfXlyfddq+qXkjw3yVsnZ3/3WGef51TVBZPnvE9W1fazGaKqXlpVZ1TV3yf5RFU9fPKYF1XVV6rqeZPt1joz3M94V9VTquqSqvp8klc+wP8ebOQEMtzTz7Q/+X14suyxSd47xnjSGOObSV4/+RSofZI8rar2uY9jvjHJZ8cYT8rMe3vvOmfTAzwwJyU5vKq2Wmf5OzLz/LdPktOSnDjG+FxmnsteM8bYd4zx/9bZ57NJ9p885y1L8gf38pi/2p5vXz9ZdkCSI8YY/y7J95M8f4zx5CS/luTtk7/kbcjfJnnVGOOA+/6RYf1cYgH3tNYlFpNrkL85xvhC2+a3quqozPwb2iHJ3km+vIFjPjXJC5JkjPHRqvr2j3togAdjjHFTVb03yauS3NpWHZDJ81eSU5P8+SwOt3OSD1TVDkk2S3LlvWy31iUWVfXSJOeNMf7trkVJ/rSqnprkziQ7JbnXs9GTuN96jPG/27zPnMW8sBZnkGF2br7rRlU9MsnRSQ6cnFH5aJLNJ6tvz4/+XW2etXnTcWChOz7JkUketoFtZvNc9j+TvGOM8YQk/yX3fD7ckJvb7cOTLE7ylMmJi29NjtWfa9OOX7OcDzZIIMP9t2VmnsC/M7murp+d+EaSp0xu/2Zbfn5mnuhTVc9Mss3cjwlw/0zO3H4wM5F8l88lOXRy+/DMXD6RJN9N8rP3cqitklwzuX3EgxhpqyTXjzF+WFW/lmS3yfJvJdlu8vqOhyZ59mT+GzPz3PwrbV643wQy3E9jjEuSfCnJV5OcnOT/tNVvTnJCVX0myR3rLH9qVV2U5OAkV83TuAD319uT9LehfFWSl1XVl5O8JMmrJ8uXJXnN5IV4e6xzjDclOWPyXDjbd8VYn9OSLK2qlZmJ3cuTZIzxwyT/PckFmXknjcvbPi9LctLkRXq3Bh4AHzUNAACNM8gAANAIZAAAaAQyAAA0AhkAABqBDAAAjUAGAIBGIAMAQPP/ASgnLS+UJygSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fraud_rate_dict = {\"Fraud\": data[\"class\"].sum(), \"Not a Fraud\": (data['class'] == False).sum()}\n",
    "\n",
    "plotDistribution(fraud_rate_dict, \"Fraud Rate\", \"\", absolute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xc1mpjx_6VLk",
    "outputId": "66a07654-6e64-4b18-da5f-6c9d68fce352"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if we don't miss any observation\n",
    "((data['class'] == False).sum() + data['class'].sum()) == data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DlyFn1w38s5o",
    "outputId": "f97b9ae7-dacf-4a7b-8490-452f0d70f1e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train fraud rate: 0.1725%\n",
      "\n",
      "y_test fraud rate: 0.1732%\n"
     ]
    }
   ],
   "source": [
    "print(f\"y_train fraud rate: {round((y_train.sum()/y_train.shape[0])*100, 4)}%\\n\")\n",
    "print(f\"y_test fraud rate: {round((y_test.sum()/y_test.shape[0])*100, 4)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Zelg7yeQ_gzD"
   },
   "outputs": [],
   "source": [
    "#TODO: dimensions reduction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ztvp3CLF_8R6",
    "outputId": "6f6505cf-d1a1-46b8-ecbe-a27b29e52661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean recall score with k=2: 0.6308\n",
      "Mean recall score with k=3: 0.6336\n",
      "Mean recall score with k=4: 0.6192\n",
      "Mean recall score with k=5: 0.6247\n",
      "Mean recall score with k=6: 0.6246\n",
      "Mean recall score with k=7: 0.6163\n",
      "Mean recall score with k=8: 0.6192\n",
      "Mean recall score with k=9: 0.6194\n",
      "Mean recall score with k=10: 0.6247\n",
      "Mean recall score with k=11: 0.6198\n"
     ]
    }
   ],
   "source": [
    "# Useless if using GridSearchCV!\n",
    "mean_recall_score = []\n",
    "for i in range(2,12):\n",
    "  stratified_k_fold = StratifiedKFold(n_splits=i, shuffle=True, random_state=55)\n",
    "\n",
    "  cv_lr_results = cross_validate(lr, x_train, y_train, cv=stratified_k_fold,\\\n",
    "                                scoring=\"recall\")\n",
    "  print(f\"Mean recall score with k={i}: {round(cv_lr_results['test_score'].sum() / len(cv_lr_results['test_score']), 4)}\")\n",
    "  mean_recall_score.append(round(cv_lr_results['test_score'].sum() / len(cv_lr_results['test_score']), 4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XsswzyIAFGJ1",
    "outputId": "8a2a2506-b0fc-430d-d613-4836368b206b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 60 candidates, totalling 180 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5212/1577299149.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                    \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratified_k_fold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                   n_jobs=-1)\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best parameters:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best recall score\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhpc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let's use GridSearchCV for testing different hyperparameters for LR\n",
    "stratified_k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=55)\n",
    "\n",
    "lr_parameters = {\"penalty\": [\"none\", \"l2\", \"l1\", \"elasticnet\"],\n",
    "                 \"solver\": [\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"],\n",
    "                 \"C\": [0.1, 1, 10]}\n",
    "\n",
    "hpc = GridSearchCV(estimator=lr, \n",
    "                   param_grid=lr_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                  n_jobs=-1)\n",
    "hpc.fit(x_train, y_train)\n",
    "print(\"Best parameters:\", hpc.best_params_)\n",
    "print(\"Best recall score\", round(hpc.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-6PL7mC-cnNf",
    "outputId": "38578f36-265f-479d-d21b-60bdc48aa50a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    }
   ],
   "source": [
    "stratified_k_fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=55)\n",
    "\n",
    "lr_parameters = {\"solver\": [\"newton-cg\", \"liblinear\"],\n",
    "                 \"max_iter\": [100, 1000, 10000, 100000]}\n",
    "\n",
    "lr_hpc = GridSearchCV(estimator=lr, \n",
    "                   param_grid=lr_parameters,\n",
    "                   scoring=\"recall\",\n",
    "                   verbose=1, \n",
    "                   cv=stratified_k_fold,\n",
    "                  n_jobs=-1)\n",
    "lr_hpc.fit(x_train, y_train)\n",
    "print(\"Best parameters:\", lr_hpc.best_params_)\n",
    "\n",
    "print(\"Best recall score\", round(lr_hpc.best_score_, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjKuOiHa0nSO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
